{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "from keras import backend\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_installs = pd.read_csv(\"../../features/entrenar_installs_final.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_installs.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_installs.drop(\"target\",axis = 1), train_installs[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "y= y.values.reshape(-1,1)\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(X))\n",
    "xscale=scaler_x.transform(X)\n",
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def build_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=13, input_dim=104))\n",
    "    regressor.add(Dense(units=1))\n",
    "    regressor.compile(loss='mse', optimizer='adam', metrics=[rmse])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 32)                2176      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 2,313\n",
      "Trainable params: 2,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=\"adam\", metrics=['mse',rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360670 samples, validate on 177644 samples\n",
      "Epoch 1/20\n",
      "360670/360670 [==============================] - 27s 76us/step - loss: 0.0877 - mean_squared_error: 0.0877 - rmse: 0.2578 - val_loss: 0.0882 - val_mean_squared_error: 0.0882 - val_rmse: 0.2561\n",
      "Epoch 2/20\n",
      "360670/360670 [==============================] - 29s 80us/step - loss: 0.0873 - mean_squared_error: 0.0873 - rmse: 0.2575 - val_loss: 0.0870 - val_mean_squared_error: 0.0870 - val_rmse: 0.2574\n",
      "Epoch 3/20\n",
      "360670/360670 [==============================] - 29s 80us/step - loss: 0.0873 - mean_squared_error: 0.0873 - rmse: 0.2575 - val_loss: 0.0870 - val_mean_squared_error: 0.0870 - val_rmse: 0.2568\n",
      "Epoch 4/20\n",
      "360670/360670 [==============================] - 27s 75us/step - loss: 0.0873 - mean_squared_error: 0.0873 - rmse: 0.2575 - val_loss: 0.0869 - val_mean_squared_error: 0.0869 - val_rmse: 0.2570\n",
      "Epoch 5/20\n",
      "360670/360670 [==============================] - 26s 72us/step - loss: 0.0873 - mean_squared_error: 0.0873 - rmse: 0.2575 - val_loss: 0.0872 - val_mean_squared_error: 0.0872 - val_rmse: 0.2565\n",
      "Epoch 6/20\n",
      "360670/360670 [==============================] - 26s 73us/step - loss: 0.0873 - mean_squared_error: 0.0873 - rmse: 0.2575 - val_loss: 0.0869 - val_mean_squared_error: 0.0869 - val_rmse: 0.2573\n",
      "Epoch 7/20\n",
      "360670/360670 [==============================] - 27s 74us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0870 - val_mean_squared_error: 0.0870 - val_rmse: 0.2574\n",
      "Epoch 8/20\n",
      "360670/360670 [==============================] - 27s 75us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0869 - val_mean_squared_error: 0.0869 - val_rmse: 0.2570\n",
      "Epoch 9/20\n",
      "360670/360670 [==============================] - 27s 75us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0869 - val_mean_squared_error: 0.0869 - val_rmse: 0.2570\n",
      "Epoch 10/20\n",
      "360670/360670 [==============================] - 28s 77us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0870 - val_mean_squared_error: 0.0870 - val_rmse: 0.2575\n",
      "Epoch 11/20\n",
      "360670/360670 [==============================] - 30s 84us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0869 - val_mean_squared_error: 0.0869 - val_rmse: 0.2569\n",
      "Epoch 12/20\n",
      "360670/360670 [==============================] - 31s 86us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0869 - val_mean_squared_error: 0.0869 - val_rmse: 0.2571\n",
      "Epoch 13/20\n",
      "360670/360670 [==============================] - 31s 86us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0871 - val_mean_squared_error: 0.0871 - val_rmse: 0.2565\n",
      "Epoch 14/20\n",
      "360670/360670 [==============================] - 30s 84us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0869 - val_mean_squared_error: 0.0869 - val_rmse: 0.2571\n",
      "Epoch 15/20\n",
      "360670/360670 [==============================] - 31s 86us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0869 - val_mean_squared_error: 0.0869 - val_rmse: 0.2570\n",
      "Epoch 16/20\n",
      "360670/360670 [==============================] - 32s 90us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0869 - val_mean_squared_error: 0.0869 - val_rmse: 0.2573\n",
      "Epoch 17/20\n",
      "360670/360670 [==============================] - 32s 90us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0871 - val_mean_squared_error: 0.0871 - val_rmse: 0.2578\n",
      "Epoch 18/20\n",
      "360670/360670 [==============================] - 34s 94us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0870 - val_mean_squared_error: 0.0870 - val_rmse: 0.2575\n",
      "Epoch 19/20\n",
      "360670/360670 [==============================] - 33s 91us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0870 - val_mean_squared_error: 0.0870 - val_rmse: 0.2568\n",
      "Epoch 20/20\n",
      "360670/360670 [==============================] - 32s 88us/step - loss: 0.0872 - mean_squared_error: 0.0872 - rmse: 0.2574 - val_loss: 0.0870 - val_mean_squared_error: 0.0870 - val_rmse: 0.2574\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, verbose=1, batch_size= 16, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mean_squared_error', 'val_rmse', 'loss', 'mean_squared_error', 'rmse'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = scaler_y.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 76430.93908489437\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred,real))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 76426.88619962845\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred,real))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 76418.94003525804\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred,real))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "real2 = []\n",
    "for valor in real:\n",
    "    real2.append(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = []\n",
    "for valor in pred:\n",
    "    pred2.append(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 66624.13320062519\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred2,real2))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>53933.877550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>156688.812692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104541.953125</td>\n",
       "      <td>50097.187391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59367.253906</td>\n",
       "      <td>2572.345044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61204.203125</td>\n",
       "      <td>80772.848565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102482.593750</td>\n",
       "      <td>93370.124332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>149232.166599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>244090.349802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>91305.718750</td>\n",
       "      <td>15812.252519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>99356.838754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31441.652344</td>\n",
       "      <td>5353.713809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54415.195312</td>\n",
       "      <td>3445.651269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-173.809509</td>\n",
       "      <td>2325.194820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7133.557129</td>\n",
       "      <td>531.741051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>88272.875000</td>\n",
       "      <td>12734.110221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1516.788940</td>\n",
       "      <td>131.947567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>182963.942958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>75833.773438</td>\n",
       "      <td>7261.235809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91089.382812</td>\n",
       "      <td>66991.784980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>82475.728245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>13431.362088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>62764.175781</td>\n",
       "      <td>3950.591228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25608.005859</td>\n",
       "      <td>244927.833927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>84814.828125</td>\n",
       "      <td>254865.783570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>61166.324219</td>\n",
       "      <td>10025.809610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>91719.867188</td>\n",
       "      <td>140996.323749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>39104.164062</td>\n",
       "      <td>11304.595296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>52274.511719</td>\n",
       "      <td>17349.214088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>232291.215384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>193609.668773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430435</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>24924.356025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430436</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>164205.120201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430437</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>11028.817206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430438</th>\n",
       "      <td>90496.796875</td>\n",
       "      <td>2335.296030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430439</th>\n",
       "      <td>56094.484375</td>\n",
       "      <td>230441.025318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430440</th>\n",
       "      <td>4955.689453</td>\n",
       "      <td>9821.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430441</th>\n",
       "      <td>79603.960938</td>\n",
       "      <td>216247.598492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430442</th>\n",
       "      <td>76589.140625</td>\n",
       "      <td>80646.159388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430443</th>\n",
       "      <td>96792.000000</td>\n",
       "      <td>56127.668504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430444</th>\n",
       "      <td>89131.421875</td>\n",
       "      <td>9899.661003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430445</th>\n",
       "      <td>70138.890625</td>\n",
       "      <td>2096.023378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430446</th>\n",
       "      <td>97446.250000</td>\n",
       "      <td>16058.010752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430447</th>\n",
       "      <td>56564.589844</td>\n",
       "      <td>24286.747478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430448</th>\n",
       "      <td>52134.601562</td>\n",
       "      <td>11539.506037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430449</th>\n",
       "      <td>30600.412109</td>\n",
       "      <td>51441.139376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430450</th>\n",
       "      <td>57255.226562</td>\n",
       "      <td>141790.447946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430451</th>\n",
       "      <td>91607.132812</td>\n",
       "      <td>77524.608704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430452</th>\n",
       "      <td>94629.531250</td>\n",
       "      <td>189846.490679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430453</th>\n",
       "      <td>90491.031250</td>\n",
       "      <td>251647.310534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430454</th>\n",
       "      <td>91241.835938</td>\n",
       "      <td>6865.639490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430455</th>\n",
       "      <td>92999.585938</td>\n",
       "      <td>47865.707975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430456</th>\n",
       "      <td>95247.382812</td>\n",
       "      <td>47288.370530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430457</th>\n",
       "      <td>100858.976562</td>\n",
       "      <td>70838.903799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430458</th>\n",
       "      <td>119382.898438</td>\n",
       "      <td>256598.554022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430459</th>\n",
       "      <td>97837.125000</td>\n",
       "      <td>165449.221638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430460</th>\n",
       "      <td>86874.976562</td>\n",
       "      <td>91078.110667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430461</th>\n",
       "      <td>55041.992188</td>\n",
       "      <td>63885.350304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430462</th>\n",
       "      <td>76595.429688</td>\n",
       "      <td>19198.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430463</th>\n",
       "      <td>60643.660156</td>\n",
       "      <td>240168.299976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430464</th>\n",
       "      <td>65482.390625</td>\n",
       "      <td>92993.177971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430465 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred           real\n",
       "0       119382.898438   53933.877550\n",
       "1       119382.898438  156688.812692\n",
       "2       104541.953125   50097.187391\n",
       "3        59367.253906    2572.345044\n",
       "4        61204.203125   80772.848565\n",
       "5       102482.593750   93370.124332\n",
       "6       119382.898438  149232.166599\n",
       "7       119382.898438  244090.349802\n",
       "8        91305.718750   15812.252519\n",
       "9       119382.898438   99356.838754\n",
       "10       31441.652344    5353.713809\n",
       "11       54415.195312    3445.651269\n",
       "12        -173.809509    2325.194820\n",
       "13        7133.557129     531.741051\n",
       "14       88272.875000   12734.110221\n",
       "15        1516.788940     131.947567\n",
       "16      119382.898438  182963.942958\n",
       "17       75833.773438    7261.235809\n",
       "18       91089.382812   66991.784980\n",
       "19      119382.898438   82475.728245\n",
       "20      119382.898438   13431.362088\n",
       "21       62764.175781    3950.591228\n",
       "22       25608.005859  244927.833927\n",
       "23       84814.828125  254865.783570\n",
       "24       61166.324219   10025.809610\n",
       "25       91719.867188  140996.323749\n",
       "26       39104.164062   11304.595296\n",
       "27       52274.511719   17349.214088\n",
       "28      119382.898438  232291.215384\n",
       "29      119382.898438  193609.668773\n",
       "...               ...            ...\n",
       "430435  119382.898438   24924.356025\n",
       "430436  119382.898438  164205.120201\n",
       "430437  119382.898438   11028.817206\n",
       "430438   90496.796875    2335.296030\n",
       "430439   56094.484375  230441.025318\n",
       "430440    4955.689453    9821.144411\n",
       "430441   79603.960938  216247.598492\n",
       "430442   76589.140625   80646.159388\n",
       "430443   96792.000000   56127.668504\n",
       "430444   89131.421875    9899.661003\n",
       "430445   70138.890625    2096.023378\n",
       "430446   97446.250000   16058.010752\n",
       "430447   56564.589844   24286.747478\n",
       "430448   52134.601562   11539.506037\n",
       "430449   30600.412109   51441.139376\n",
       "430450   57255.226562  141790.447946\n",
       "430451   91607.132812   77524.608704\n",
       "430452   94629.531250  189846.490679\n",
       "430453   90491.031250  251647.310534\n",
       "430454   91241.835938    6865.639490\n",
       "430455   92999.585938   47865.707975\n",
       "430456   95247.382812   47288.370530\n",
       "430457  100858.976562   70838.903799\n",
       "430458  119382.898438  256598.554022\n",
       "430459   97837.125000  165449.221638\n",
       "430460   86874.976562   91078.110667\n",
       "430461   55041.992188   63885.350304\n",
       "430462   76595.429688   19198.038416\n",
       "430463   60643.660156  240168.299976\n",
       "430464   65482.390625   92993.177971\n",
       "\n",
       "[430465 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"pred\":pred2,\"real\":real2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"../../../modelo/armado_datos/train_completo_auctions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20154878421450015"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train[\"target\"].max().sum())/ len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286041"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximo = train[\"target\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximos = train[train[\"target\"] == maximo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"target\"] != maximo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.append(maximos.sample(150000,random_state = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del maximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.drop(\"target\",axis = 1), train[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073544, 103)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= y.values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(X))\n",
    "xscale=scaler_x.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def build_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=13, input_dim=104))\n",
    "    regressor.add(Dense(units=1))\n",
    "    regressor.compile(loss='mse', optimizer='adam', metrics=[rmse])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0624 21:29:41.713503 140308775319360 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0624 21:29:42.096714 140308775319360 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0624 21:29:42.183354 140308775319360 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0624 21:29:42.216489 140308775319360 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                5200      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 408       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 5,617\n",
      "Trainable params: 5,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=103, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0624 21:29:42.256882 140308775319360 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='SDG', metrics=['mse',rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0624 21:29:42.909635 140308775319360 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 858835 samples, validate on 214709 samples\n",
      "Epoch 1/100\n",
      "858835/858835 [==============================] - 20s 23us/step - loss: 0.1005 - mean_squared_error: 0.1005 - rmse: 0.2580 - val_loss: 0.0994 - val_mean_squared_error: 0.0994 - val_rmse: 0.2599\n",
      "Epoch 2/100\n",
      "858835/858835 [==============================] - 18s 21us/step - loss: 0.0993 - mean_squared_error: 0.0993 - rmse: 0.2563 - val_loss: 0.0989 - val_mean_squared_error: 0.0989 - val_rmse: 0.2567\n",
      "Epoch 3/100\n",
      "858835/858835 [==============================] - 18s 20us/step - loss: 0.0990 - mean_squared_error: 0.0990 - rmse: 0.2556 - val_loss: 0.0985 - val_mean_squared_error: 0.0985 - val_rmse: 0.2538\n",
      "Epoch 4/100\n",
      "858835/858835 [==============================] - 18s 21us/step - loss: 0.0987 - mean_squared_error: 0.0987 - rmse: 0.2552 - val_loss: 0.0990 - val_mean_squared_error: 0.0990 - val_rmse: 0.2508\n",
      "Epoch 5/100\n",
      "858835/858835 [==============================] - 18s 21us/step - loss: 0.0986 - mean_squared_error: 0.0986 - rmse: 0.2549 - val_loss: 0.0984 - val_mean_squared_error: 0.0984 - val_rmse: 0.2522\n",
      "Epoch 6/100\n",
      "858835/858835 [==============================] - 18s 21us/step - loss: 0.0985 - mean_squared_error: 0.0985 - rmse: 0.2547 - val_loss: 0.0982 - val_mean_squared_error: 0.0982 - val_rmse: 0.2533\n",
      "Epoch 7/100\n",
      "858835/858835 [==============================] - 18s 21us/step - loss: 0.0984 - mean_squared_error: 0.0984 - rmse: 0.2546 - val_loss: 0.0983 - val_mean_squared_error: 0.0983 - val_rmse: 0.2543\n",
      "Epoch 8/100\n",
      "858835/858835 [==============================] - 18s 21us/step - loss: 0.0983 - mean_squared_error: 0.0983 - rmse: 0.2544 - val_loss: 0.0982 - val_mean_squared_error: 0.0982 - val_rmse: 0.2547\n",
      "Epoch 9/100\n",
      "858835/858835 [==============================] - 19s 22us/step - loss: 0.0983 - mean_squared_error: 0.0983 - rmse: 0.2544 - val_loss: 0.0982 - val_mean_squared_error: 0.0982 - val_rmse: 0.2553\n",
      "Epoch 10/100\n",
      "858835/858835 [==============================] - 19s 22us/step - loss: 0.0983 - mean_squared_error: 0.0983 - rmse: 0.2543 - val_loss: 0.0982 - val_mean_squared_error: 0.0982 - val_rmse: 0.2536\n",
      "Epoch 11/100\n",
      "858835/858835 [==============================] - 19s 22us/step - loss: 0.0982 - mean_squared_error: 0.0982 - rmse: 0.2542 - val_loss: 0.0981 - val_mean_squared_error: 0.0981 - val_rmse: 0.2544\n",
      "Epoch 12/100\n",
      "858835/858835 [==============================] - 19s 22us/step - loss: 0.0982 - mean_squared_error: 0.0982 - rmse: 0.2542 - val_loss: 0.0981 - val_mean_squared_error: 0.0981 - val_rmse: 0.2556\n",
      "Epoch 13/100\n",
      "858835/858835 [==============================] - 19s 22us/step - loss: 0.0982 - mean_squared_error: 0.0982 - rmse: 0.2542 - val_loss: 0.0983 - val_mean_squared_error: 0.0983 - val_rmse: 0.2529\n",
      "Epoch 14/100\n",
      "858835/858835 [==============================] - 20s 23us/step - loss: 0.0981 - mean_squared_error: 0.0981 - rmse: 0.2541 - val_loss: 0.0981 - val_mean_squared_error: 0.0981 - val_rmse: 0.2534\n",
      "Epoch 15/100\n",
      "858835/858835 [==============================] - 20s 23us/step - loss: 0.0981 - mean_squared_error: 0.0981 - rmse: 0.2540 - val_loss: 0.0983 - val_mean_squared_error: 0.0983 - val_rmse: 0.2520\n",
      "Epoch 16/100\n",
      "858835/858835 [==============================] - 20s 24us/step - loss: 0.0981 - mean_squared_error: 0.0981 - rmse: 0.2540 - val_loss: 0.0983 - val_mean_squared_error: 0.0983 - val_rmse: 0.2537\n",
      "Epoch 17/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0981 - mean_squared_error: 0.0981 - rmse: 0.2540 - val_loss: 0.0980 - val_mean_squared_error: 0.0980 - val_rmse: 0.2533\n",
      "Epoch 18/100\n",
      "858835/858835 [==============================] - 20s 24us/step - loss: 0.0980 - mean_squared_error: 0.0980 - rmse: 0.2539 - val_loss: 0.0982 - val_mean_squared_error: 0.0982 - val_rmse: 0.2557\n",
      "Epoch 19/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0980 - mean_squared_error: 0.0980 - rmse: 0.2539 - val_loss: 0.0981 - val_mean_squared_error: 0.0981 - val_rmse: 0.2551\n",
      "Epoch 20/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0980 - mean_squared_error: 0.0980 - rmse: 0.2539 - val_loss: 0.0982 - val_mean_squared_error: 0.0982 - val_rmse: 0.2530\n",
      "Epoch 21/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0980 - mean_squared_error: 0.0980 - rmse: 0.2539 - val_loss: 0.0984 - val_mean_squared_error: 0.0984 - val_rmse: 0.2571\n",
      "Epoch 22/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0980 - mean_squared_error: 0.0980 - rmse: 0.2539 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2526\n",
      "Epoch 23/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0980 - mean_squared_error: 0.0980 - rmse: 0.2538 - val_loss: 0.0986 - val_mean_squared_error: 0.0986 - val_rmse: 0.2596\n",
      "Epoch 24/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0979 - mean_squared_error: 0.0979 - rmse: 0.2538 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2538\n",
      "Epoch 25/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0979 - mean_squared_error: 0.0979 - rmse: 0.2538 - val_loss: 0.0981 - val_mean_squared_error: 0.0981 - val_rmse: 0.2542\n",
      "Epoch 26/100\n",
      "858835/858835 [==============================] - 22s 25us/step - loss: 0.0979 - mean_squared_error: 0.0979 - rmse: 0.2537 - val_loss: 0.0982 - val_mean_squared_error: 0.0982 - val_rmse: 0.2514\n",
      "Epoch 27/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0979 - mean_squared_error: 0.0979 - rmse: 0.2537 - val_loss: 0.0980 - val_mean_squared_error: 0.0980 - val_rmse: 0.2530\n",
      "Epoch 28/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0979 - mean_squared_error: 0.0979 - rmse: 0.2537 - val_loss: 0.0980 - val_mean_squared_error: 0.0980 - val_rmse: 0.2532\n",
      "Epoch 29/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0979 - mean_squared_error: 0.0979 - rmse: 0.2537 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2532\n",
      "Epoch 30/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0979 - mean_squared_error: 0.0979 - rmse: 0.2536 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2541\n",
      "Epoch 31/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0979 - mean_squared_error: 0.0979 - rmse: 0.2536 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2540\n",
      "Epoch 32/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0978 - mean_squared_error: 0.0978 - rmse: 0.2536 - val_loss: 0.0982 - val_mean_squared_error: 0.0982 - val_rmse: 0.2553\n",
      "Epoch 33/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0978 - mean_squared_error: 0.0978 - rmse: 0.2536 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2525\n",
      "Epoch 34/100\n",
      "858835/858835 [==============================] - 21s 25us/step - loss: 0.0978 - mean_squared_error: 0.0978 - rmse: 0.2536 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2538\n",
      "Epoch 35/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0978 - mean_squared_error: 0.0978 - rmse: 0.2535 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2547\n",
      "Epoch 36/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0978 - mean_squared_error: 0.0978 - rmse: 0.2535 - val_loss: 0.0980 - val_mean_squared_error: 0.0980 - val_rmse: 0.2551\n",
      "Epoch 37/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0978 - mean_squared_error: 0.0978 - rmse: 0.2535 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2516\n",
      "Epoch 38/100\n",
      "858835/858835 [==============================] - 21s 24us/step - loss: 0.0978 - mean_squared_error: 0.0978 - rmse: 0.2535 - val_loss: 0.0979 - val_mean_squared_error: 0.0979 - val_rmse: 0.2547\n",
      "Epoch 39/100\n",
      "837750/858835 [============================>.] - ETA: 0s - loss: 0.0978 - mean_squared_error: 0.0978 - rmse: 0.2535"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=50,  verbose=1, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = scaler_y.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 81211.81519164734\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred,real))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras_auctions_reducido.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediccion competencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_competencia = pd.read_pickle(\"../../../analisis/solo_competencia/armado_features/features_completos_competencia.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_competencia.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4037, 102)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_competencia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = features_competencia.iloc[1,:24].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x_comp = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_comp =scaler_x_comp.fit_transform(features_competencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "real2 = []\n",
    "for valor in real:\n",
    "    real2.append(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = []\n",
    "for valor in pred:\n",
    "    pred2.append(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 46782.89622217884\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred2,real2))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254071.625000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250365.828125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250677.875000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>254244.421875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130438.468750</td>\n",
       "      <td>6885.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>253830.453125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>253495.984375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251706.750000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>126759.046875</td>\n",
       "      <td>58330.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>253883.453125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>254606.296875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>253890.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>254033.000000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>254545.234375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>248110.359375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>252842.343750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>253453.609375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>251201.171875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>124572.859375</td>\n",
       "      <td>251329.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>254243.656250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>254595.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>254673.109375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>130871.671875</td>\n",
       "      <td>157004.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>259229.187500</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>254475.984375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>254298.703125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>254165.718750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>254342.234375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>250820.531250</td>\n",
       "      <td>107940.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>254613.000000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147485</th>\n",
       "      <td>253645.937500</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147486</th>\n",
       "      <td>253896.328125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147487</th>\n",
       "      <td>254247.718750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147488</th>\n",
       "      <td>254625.265625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147489</th>\n",
       "      <td>246235.250000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147490</th>\n",
       "      <td>254466.750000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147491</th>\n",
       "      <td>126846.382812</td>\n",
       "      <td>29903.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147492</th>\n",
       "      <td>253718.890625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147493</th>\n",
       "      <td>254544.171875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147494</th>\n",
       "      <td>128345.734375</td>\n",
       "      <td>13029.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147495</th>\n",
       "      <td>254591.531250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147496</th>\n",
       "      <td>253837.125000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147497</th>\n",
       "      <td>245426.656250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147498</th>\n",
       "      <td>135537.375000</td>\n",
       "      <td>172094.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147499</th>\n",
       "      <td>254644.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147500</th>\n",
       "      <td>250777.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147501</th>\n",
       "      <td>254551.031250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147502</th>\n",
       "      <td>130438.468750</td>\n",
       "      <td>59264.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147503</th>\n",
       "      <td>253134.875000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147504</th>\n",
       "      <td>253657.453125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147505</th>\n",
       "      <td>254669.343750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147506</th>\n",
       "      <td>124639.265625</td>\n",
       "      <td>194662.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147507</th>\n",
       "      <td>125306.320312</td>\n",
       "      <td>6907.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147508</th>\n",
       "      <td>254432.859375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147509</th>\n",
       "      <td>252354.500000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147510</th>\n",
       "      <td>251663.531250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147511</th>\n",
       "      <td>124028.742188</td>\n",
       "      <td>179345.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147512</th>\n",
       "      <td>253056.562500</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147513</th>\n",
       "      <td>253004.156250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147514</th>\n",
       "      <td>124135.101562</td>\n",
       "      <td>67690.731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147515 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred        real\n",
       "0       254071.625000  259200.000\n",
       "1       250365.828125  259200.000\n",
       "2       250677.875000  259200.000\n",
       "3       254244.421875  259200.000\n",
       "4       130438.468750    6885.802\n",
       "5       253830.453125  259200.000\n",
       "6       253495.984375  259200.000\n",
       "7       251706.750000  259200.000\n",
       "8       126759.046875   58330.013\n",
       "9       253883.453125  259200.000\n",
       "10      254606.296875  259200.000\n",
       "11      253890.515625  259200.000\n",
       "12      254033.000000  259200.000\n",
       "13      254545.234375  259200.000\n",
       "14      248110.359375  259200.000\n",
       "15      252842.343750  259200.000\n",
       "16      253453.609375  259200.000\n",
       "17      251201.171875  259200.000\n",
       "18      124572.859375  251329.528\n",
       "19      254243.656250  259200.000\n",
       "20      254595.515625  259200.000\n",
       "21      254673.109375  259200.000\n",
       "22      130871.671875  157004.823\n",
       "23      259229.187500  259200.000\n",
       "24      254475.984375  259200.000\n",
       "25      254298.703125  259200.000\n",
       "26      254165.718750  259200.000\n",
       "27      254342.234375  259200.000\n",
       "28      250820.531250  107940.938\n",
       "29      254613.000000  259200.000\n",
       "...               ...         ...\n",
       "147485  253645.937500  259200.000\n",
       "147486  253896.328125  259200.000\n",
       "147487  254247.718750  259200.000\n",
       "147488  254625.265625  259200.000\n",
       "147489  246235.250000  259200.000\n",
       "147490  254466.750000  259200.000\n",
       "147491  126846.382812   29903.955\n",
       "147492  253718.890625  259200.000\n",
       "147493  254544.171875  259200.000\n",
       "147494  128345.734375   13029.522\n",
       "147495  254591.531250  259200.000\n",
       "147496  253837.125000  259200.000\n",
       "147497  245426.656250  259200.000\n",
       "147498  135537.375000  172094.437\n",
       "147499  254644.515625  259200.000\n",
       "147500  250777.515625  259200.000\n",
       "147501  254551.031250  259200.000\n",
       "147502  130438.468750   59264.239\n",
       "147503  253134.875000  259200.000\n",
       "147504  253657.453125  259200.000\n",
       "147505  254669.343750  259200.000\n",
       "147506  124639.265625  194662.671\n",
       "147507  125306.320312    6907.243\n",
       "147508  254432.859375  259200.000\n",
       "147509  252354.500000  259200.000\n",
       "147510  251663.531250  259200.000\n",
       "147511  124028.742188  179345.230\n",
       "147512  253056.562500  259200.000\n",
       "147513  253004.156250  259200.000\n",
       "147514  124135.101562   67690.731\n",
       "\n",
       "[147515 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"pred\":pred2,\"real\":real2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
