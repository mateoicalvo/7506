{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "from keras import backend\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"../../../modelo/armado_datos/train_completo_installs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"cantidad_nans\"] = train.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"cantidad_nans\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"cantidad_nans\"] < 103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.drop(\"target\",axis = 1), train[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "y= y.values.reshape(-1,1)\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(X))\n",
    "xscale=scaler_x.transform(X)\n",
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def build_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=13, input_dim=104))\n",
    "    regressor.add(Dense(units=1))\n",
    "    regressor.compile(loss='mse', optimizer='adam', metrics=[rmse])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 21:45:59.997907 140238992508736 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0623 21:46:01.007956 140238992508736 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0623 21:46:01.131473 140238992508736 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0623 21:46:01.192604 140238992508736 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                1260      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,373\n",
      "Trainable params: 1,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=104, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 21:48:23.402250 140238992508736 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse',rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 21:48:26.361136 140238992508736 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 590060 samples, validate on 147515 samples\n",
      "Epoch 1/100\n",
      "590060/590060 [==============================] - 13s 23us/step - loss: 0.0359 - mean_squared_error: 0.0359 - rmse: 0.1047 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0958\n",
      "Epoch 2/100\n",
      "590060/590060 [==============================] - 12s 20us/step - loss: 0.0326 - mean_squared_error: 0.0326 - rmse: 0.0961 - val_loss: 0.0327 - val_mean_squared_error: 0.0327 - val_rmse: 0.0898\n",
      "Epoch 3/100\n",
      "590060/590060 [==============================] - 12s 20us/step - loss: 0.0326 - mean_squared_error: 0.0326 - rmse: 0.0956 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0967\n",
      "Epoch 4/100\n",
      "590060/590060 [==============================] - 12s 20us/step - loss: 0.0325 - mean_squared_error: 0.0325 - rmse: 0.0952 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0909\n",
      "Epoch 5/100\n",
      "590060/590060 [==============================] - 12s 20us/step - loss: 0.0325 - mean_squared_error: 0.0325 - rmse: 0.0951 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0921\n",
      "Epoch 6/100\n",
      "590060/590060 [==============================] - 12s 21us/step - loss: 0.0325 - mean_squared_error: 0.0325 - rmse: 0.0949 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0913\n",
      "Epoch 7/100\n",
      "590060/590060 [==============================] - 12s 20us/step - loss: 0.0325 - mean_squared_error: 0.0325 - rmse: 0.0948 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0990\n",
      "Epoch 8/100\n",
      "590060/590060 [==============================] - 12s 21us/step - loss: 0.0325 - mean_squared_error: 0.0325 - rmse: 0.0948 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.1007\n",
      "Epoch 9/100\n",
      "590060/590060 [==============================] - 12s 21us/step - loss: 0.0325 - mean_squared_error: 0.0325 - rmse: 0.0948 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.0889\n",
      "Epoch 10/100\n",
      "590060/590060 [==============================] - 12s 21us/step - loss: 0.0325 - mean_squared_error: 0.0325 - rmse: 0.0947 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0922\n",
      "Epoch 11/100\n",
      "590060/590060 [==============================] - 12s 21us/step - loss: 0.0325 - mean_squared_error: 0.0325 - rmse: 0.0947 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0912\n",
      "Epoch 12/100\n",
      "590060/590060 [==============================] - 13s 21us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0947 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0904\n",
      "Epoch 13/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0947 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0912\n",
      "Epoch 14/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0947 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0966\n",
      "Epoch 15/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0946 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0975\n",
      "Epoch 16/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0946 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0990\n",
      "Epoch 17/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0946 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0953\n",
      "Epoch 18/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0946 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.0997\n",
      "Epoch 19/100\n",
      "590060/590060 [==============================] - 13s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0946 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0962\n",
      "Epoch 20/100\n",
      "590060/590060 [==============================] - 14s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0946 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.1008\n",
      "Epoch 21/100\n",
      "590060/590060 [==============================] - 14s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0946 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0901\n",
      "Epoch 22/100\n",
      "590060/590060 [==============================] - 14s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0946 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0915\n",
      "Epoch 23/100\n",
      "590060/590060 [==============================] - 14s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0945 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0997\n",
      "Epoch 24/100\n",
      "590060/590060 [==============================] - 14s 24us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0945 - val_loss: 0.0324 - val_mean_squared_error: 0.0324 - val_rmse: 0.0933\n",
      "Epoch 25/100\n",
      "590060/590060 [==============================] - 14s 24us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0945 - val_loss: 0.0327 - val_mean_squared_error: 0.0327 - val_rmse: 0.1063\n",
      "Epoch 26/100\n",
      "590060/590060 [==============================] - 14s 24us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0945 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0963\n",
      "Epoch 27/100\n",
      "590060/590060 [==============================] - 14s 24us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0945 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.1021\n",
      "Epoch 28/100\n",
      "590060/590060 [==============================] - 14s 24us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0945 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0991\n",
      "Epoch 29/100\n",
      "590060/590060 [==============================] - 14s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0945 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0896\n",
      "Epoch 30/100\n",
      "590060/590060 [==============================] - 14s 24us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0945 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0910\n",
      "Epoch 31/100\n",
      "590060/590060 [==============================] - 14s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0916\n",
      "Epoch 32/100\n",
      "590060/590060 [==============================] - 14s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0951\n",
      "Epoch 33/100\n",
      "590060/590060 [==============================] - 14s 24us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0926\n",
      "Epoch 34/100\n",
      "590060/590060 [==============================] - 13s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0958\n",
      "Epoch 35/100\n",
      "590060/590060 [==============================] - 13s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0930\n",
      "Epoch 36/100\n",
      "590060/590060 [==============================] - 13s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0956\n",
      "Epoch 37/100\n",
      "590060/590060 [==============================] - 13s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0902\n",
      "Epoch 38/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0940\n",
      "Epoch 39/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0961\n",
      "Epoch 40/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0990\n",
      "Epoch 41/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0883\n",
      "Epoch 42/100\n",
      "590060/590060 [==============================] - 13s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0898\n",
      "Epoch 43/100\n",
      "590060/590060 [==============================] - 13s 23us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0902\n",
      "Epoch 44/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0324 - val_mean_squared_error: 0.0324 - val_rmse: 0.0927\n",
      "Epoch 45/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0988\n",
      "Epoch 46/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0928\n",
      "Epoch 47/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0918\n",
      "Epoch 48/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0324 - mean_squared_error: 0.0324 - rmse: 0.0944 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.1013\n",
      "Epoch 49/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0939\n",
      "Epoch 50/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0907\n",
      "Epoch 51/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0927\n",
      "Epoch 52/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0969\n",
      "Epoch 53/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0944 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0958\n",
      "Epoch 54/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0983\n",
      "Epoch 55/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0929\n",
      "Epoch 56/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0963\n",
      "Epoch 57/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0968\n",
      "Epoch 58/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.1005\n",
      "Epoch 59/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0327 - val_mean_squared_error: 0.0327 - val_rmse: 0.0870\n",
      "Epoch 60/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0908\n",
      "Epoch 61/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.0978\n",
      "Epoch 62/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.1017\n",
      "Epoch 63/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0962\n",
      "Epoch 64/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.0942\n",
      "Epoch 65/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0937\n",
      "Epoch 66/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0955\n",
      "Epoch 67/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0936\n",
      "Epoch 68/100\n",
      "590060/590060 [==============================] - 13s 22us/step - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0888\n",
      "Epoch 69/100\n",
      "414450/590060 [====================>.........] - ETA: 3s - loss: 0.0323 - mean_squared_error: 0.0323 - rmse: 0.0943"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=50,  verbose=1, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mean_squared_error', 'val_mean_absolute_error', 'val_rmse', 'loss', 'mean_squared_error', 'mean_absolute_error', 'rmse'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = scaler_y.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 46782.89622217884\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred,real))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "real2 = []\n",
    "for valor in real:\n",
    "    real2.append(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = []\n",
    "for valor in pred:\n",
    "    pred2.append(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 46782.89622217884\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred2,real2))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254071.625000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250365.828125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250677.875000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>254244.421875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130438.468750</td>\n",
       "      <td>6885.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>253830.453125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>253495.984375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251706.750000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>126759.046875</td>\n",
       "      <td>58330.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>253883.453125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>254606.296875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>253890.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>254033.000000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>254545.234375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>248110.359375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>252842.343750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>253453.609375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>251201.171875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>124572.859375</td>\n",
       "      <td>251329.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>254243.656250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>254595.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>254673.109375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>130871.671875</td>\n",
       "      <td>157004.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>259229.187500</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>254475.984375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>254298.703125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>254165.718750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>254342.234375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>250820.531250</td>\n",
       "      <td>107940.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>254613.000000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147485</th>\n",
       "      <td>253645.937500</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147486</th>\n",
       "      <td>253896.328125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147487</th>\n",
       "      <td>254247.718750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147488</th>\n",
       "      <td>254625.265625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147489</th>\n",
       "      <td>246235.250000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147490</th>\n",
       "      <td>254466.750000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147491</th>\n",
       "      <td>126846.382812</td>\n",
       "      <td>29903.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147492</th>\n",
       "      <td>253718.890625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147493</th>\n",
       "      <td>254544.171875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147494</th>\n",
       "      <td>128345.734375</td>\n",
       "      <td>13029.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147495</th>\n",
       "      <td>254591.531250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147496</th>\n",
       "      <td>253837.125000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147497</th>\n",
       "      <td>245426.656250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147498</th>\n",
       "      <td>135537.375000</td>\n",
       "      <td>172094.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147499</th>\n",
       "      <td>254644.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147500</th>\n",
       "      <td>250777.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147501</th>\n",
       "      <td>254551.031250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147502</th>\n",
       "      <td>130438.468750</td>\n",
       "      <td>59264.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147503</th>\n",
       "      <td>253134.875000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147504</th>\n",
       "      <td>253657.453125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147505</th>\n",
       "      <td>254669.343750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147506</th>\n",
       "      <td>124639.265625</td>\n",
       "      <td>194662.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147507</th>\n",
       "      <td>125306.320312</td>\n",
       "      <td>6907.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147508</th>\n",
       "      <td>254432.859375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147509</th>\n",
       "      <td>252354.500000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147510</th>\n",
       "      <td>251663.531250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147511</th>\n",
       "      <td>124028.742188</td>\n",
       "      <td>179345.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147512</th>\n",
       "      <td>253056.562500</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147513</th>\n",
       "      <td>253004.156250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147514</th>\n",
       "      <td>124135.101562</td>\n",
       "      <td>67690.731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147515 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred        real\n",
       "0       254071.625000  259200.000\n",
       "1       250365.828125  259200.000\n",
       "2       250677.875000  259200.000\n",
       "3       254244.421875  259200.000\n",
       "4       130438.468750    6885.802\n",
       "5       253830.453125  259200.000\n",
       "6       253495.984375  259200.000\n",
       "7       251706.750000  259200.000\n",
       "8       126759.046875   58330.013\n",
       "9       253883.453125  259200.000\n",
       "10      254606.296875  259200.000\n",
       "11      253890.515625  259200.000\n",
       "12      254033.000000  259200.000\n",
       "13      254545.234375  259200.000\n",
       "14      248110.359375  259200.000\n",
       "15      252842.343750  259200.000\n",
       "16      253453.609375  259200.000\n",
       "17      251201.171875  259200.000\n",
       "18      124572.859375  251329.528\n",
       "19      254243.656250  259200.000\n",
       "20      254595.515625  259200.000\n",
       "21      254673.109375  259200.000\n",
       "22      130871.671875  157004.823\n",
       "23      259229.187500  259200.000\n",
       "24      254475.984375  259200.000\n",
       "25      254298.703125  259200.000\n",
       "26      254165.718750  259200.000\n",
       "27      254342.234375  259200.000\n",
       "28      250820.531250  107940.938\n",
       "29      254613.000000  259200.000\n",
       "...               ...         ...\n",
       "147485  253645.937500  259200.000\n",
       "147486  253896.328125  259200.000\n",
       "147487  254247.718750  259200.000\n",
       "147488  254625.265625  259200.000\n",
       "147489  246235.250000  259200.000\n",
       "147490  254466.750000  259200.000\n",
       "147491  126846.382812   29903.955\n",
       "147492  253718.890625  259200.000\n",
       "147493  254544.171875  259200.000\n",
       "147494  128345.734375   13029.522\n",
       "147495  254591.531250  259200.000\n",
       "147496  253837.125000  259200.000\n",
       "147497  245426.656250  259200.000\n",
       "147498  135537.375000  172094.437\n",
       "147499  254644.515625  259200.000\n",
       "147500  250777.515625  259200.000\n",
       "147501  254551.031250  259200.000\n",
       "147502  130438.468750   59264.239\n",
       "147503  253134.875000  259200.000\n",
       "147504  253657.453125  259200.000\n",
       "147505  254669.343750  259200.000\n",
       "147506  124639.265625  194662.671\n",
       "147507  125306.320312    6907.243\n",
       "147508  254432.859375  259200.000\n",
       "147509  252354.500000  259200.000\n",
       "147510  251663.531250  259200.000\n",
       "147511  124028.742188  179345.230\n",
       "147512  253056.562500  259200.000\n",
       "147513  253004.156250  259200.000\n",
       "147514  124135.101562   67690.731\n",
       "\n",
       "[147515 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"pred\":pred2,\"real\":real2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"../../../modelo/armado_datos/train_completo_auctions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286041"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.drop(\"target\",axis = 1), train[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= y.values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-55a396d57dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscaler_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    351\u001b[0m         X = check_array(X, copy=self.copy,\n\u001b[1;32m    352\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5378\u001b[0m                [nan,  3.]])\n\u001b[1;32m   5379\u001b[0m         \"\"\"\n\u001b[0;32m-> 5380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dtype_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5323\u001b[0m         \"\"\"\n\u001b[1;32m   5324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5327\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mas_array\u001b[0;34m(self, transpose, items)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtranspose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'object'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mitemmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(X))\n",
    "xscale=scaler_x.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def build_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=13, input_dim=104))\n",
    "    regressor.add(Dense(units=1))\n",
    "    regressor.compile(loss='mse', optimizer='adam', metrics=[rmse])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 20:49:21.068512 139911943796544 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0623 20:49:23.196177 139911943796544 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0623 20:49:23.479867 139911943796544 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0623 20:49:23.740615 139911943796544 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                1260      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,373\n",
      "Trainable params: 1,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=103, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 20:51:50.858865 139911943796544 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse',rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 20:52:18.733414 139911943796544 deprecation_wrapper.py:119] From /home/pelozo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 590060 samples, validate on 147515 samples\n",
      "Epoch 1/10\n",
      "590060/590060 [==============================] - 14s 24us/step - loss: 0.0400 - mean_squared_error: 0.0400 - rmse: 0.1079 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.0947\n",
      "Epoch 2/10\n",
      "590060/590060 [==============================] - 11s 19us/step - loss: 0.0327 - mean_squared_error: 0.0327 - rmse: 0.0960 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.0914\n",
      "Epoch 3/10\n",
      "590060/590060 [==============================] - 11s 19us/step - loss: 0.0326 - mean_squared_error: 0.0326 - rmse: 0.0957 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.0943\n",
      "Epoch 4/10\n",
      "590060/590060 [==============================] - 12s 20us/step - loss: 0.0326 - mean_squared_error: 0.0326 - rmse: 0.0954 - val_loss: 0.0325 - val_mean_squared_error: 0.0325 - val_rmse: 0.0966\n",
      "Epoch 5/10\n",
      "590060/590060 [==============================] - 13s 21us/step - loss: 0.0325 - mean_squared_error: 0.0325 - rmse: 0.0952 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_rmse: 0.1014\n",
      "Epoch 6/10\n",
      "255150/590060 [===========>..................] - ETA: 6s - loss: 0.0326 - mean_squared_error: 0.0326 - rmse: 0.0951"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=50,  verbose=1, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mean_squared_error', 'val_mean_absolute_error', 'val_rmse', 'loss', 'mean_squared_error', 'mean_absolute_error', 'rmse'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = scaler_y.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 46782.89622217884\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred,real))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "real2 = []\n",
    "for valor in real:\n",
    "    real2.append(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = []\n",
    "for valor in pred:\n",
    "    pred2.append(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 46782.89622217884\n"
     ]
    }
   ],
   "source": [
    "error = sqrt(mean_squared_error(pred2,real2))\n",
    "\n",
    "print('RMSE value is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254071.625000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250365.828125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250677.875000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>254244.421875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130438.468750</td>\n",
       "      <td>6885.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>253830.453125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>253495.984375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251706.750000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>126759.046875</td>\n",
       "      <td>58330.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>253883.453125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>254606.296875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>253890.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>254033.000000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>254545.234375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>248110.359375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>252842.343750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>253453.609375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>251201.171875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>124572.859375</td>\n",
       "      <td>251329.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>254243.656250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>254595.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>254673.109375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>130871.671875</td>\n",
       "      <td>157004.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>259229.187500</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>254475.984375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>254298.703125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>254165.718750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>254342.234375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>250820.531250</td>\n",
       "      <td>107940.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>254613.000000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147485</th>\n",
       "      <td>253645.937500</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147486</th>\n",
       "      <td>253896.328125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147487</th>\n",
       "      <td>254247.718750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147488</th>\n",
       "      <td>254625.265625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147489</th>\n",
       "      <td>246235.250000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147490</th>\n",
       "      <td>254466.750000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147491</th>\n",
       "      <td>126846.382812</td>\n",
       "      <td>29903.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147492</th>\n",
       "      <td>253718.890625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147493</th>\n",
       "      <td>254544.171875</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147494</th>\n",
       "      <td>128345.734375</td>\n",
       "      <td>13029.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147495</th>\n",
       "      <td>254591.531250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147496</th>\n",
       "      <td>253837.125000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147497</th>\n",
       "      <td>245426.656250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147498</th>\n",
       "      <td>135537.375000</td>\n",
       "      <td>172094.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147499</th>\n",
       "      <td>254644.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147500</th>\n",
       "      <td>250777.515625</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147501</th>\n",
       "      <td>254551.031250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147502</th>\n",
       "      <td>130438.468750</td>\n",
       "      <td>59264.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147503</th>\n",
       "      <td>253134.875000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147504</th>\n",
       "      <td>253657.453125</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147505</th>\n",
       "      <td>254669.343750</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147506</th>\n",
       "      <td>124639.265625</td>\n",
       "      <td>194662.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147507</th>\n",
       "      <td>125306.320312</td>\n",
       "      <td>6907.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147508</th>\n",
       "      <td>254432.859375</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147509</th>\n",
       "      <td>252354.500000</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147510</th>\n",
       "      <td>251663.531250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147511</th>\n",
       "      <td>124028.742188</td>\n",
       "      <td>179345.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147512</th>\n",
       "      <td>253056.562500</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147513</th>\n",
       "      <td>253004.156250</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147514</th>\n",
       "      <td>124135.101562</td>\n",
       "      <td>67690.731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147515 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred        real\n",
       "0       254071.625000  259200.000\n",
       "1       250365.828125  259200.000\n",
       "2       250677.875000  259200.000\n",
       "3       254244.421875  259200.000\n",
       "4       130438.468750    6885.802\n",
       "5       253830.453125  259200.000\n",
       "6       253495.984375  259200.000\n",
       "7       251706.750000  259200.000\n",
       "8       126759.046875   58330.013\n",
       "9       253883.453125  259200.000\n",
       "10      254606.296875  259200.000\n",
       "11      253890.515625  259200.000\n",
       "12      254033.000000  259200.000\n",
       "13      254545.234375  259200.000\n",
       "14      248110.359375  259200.000\n",
       "15      252842.343750  259200.000\n",
       "16      253453.609375  259200.000\n",
       "17      251201.171875  259200.000\n",
       "18      124572.859375  251329.528\n",
       "19      254243.656250  259200.000\n",
       "20      254595.515625  259200.000\n",
       "21      254673.109375  259200.000\n",
       "22      130871.671875  157004.823\n",
       "23      259229.187500  259200.000\n",
       "24      254475.984375  259200.000\n",
       "25      254298.703125  259200.000\n",
       "26      254165.718750  259200.000\n",
       "27      254342.234375  259200.000\n",
       "28      250820.531250  107940.938\n",
       "29      254613.000000  259200.000\n",
       "...               ...         ...\n",
       "147485  253645.937500  259200.000\n",
       "147486  253896.328125  259200.000\n",
       "147487  254247.718750  259200.000\n",
       "147488  254625.265625  259200.000\n",
       "147489  246235.250000  259200.000\n",
       "147490  254466.750000  259200.000\n",
       "147491  126846.382812   29903.955\n",
       "147492  253718.890625  259200.000\n",
       "147493  254544.171875  259200.000\n",
       "147494  128345.734375   13029.522\n",
       "147495  254591.531250  259200.000\n",
       "147496  253837.125000  259200.000\n",
       "147497  245426.656250  259200.000\n",
       "147498  135537.375000  172094.437\n",
       "147499  254644.515625  259200.000\n",
       "147500  250777.515625  259200.000\n",
       "147501  254551.031250  259200.000\n",
       "147502  130438.468750   59264.239\n",
       "147503  253134.875000  259200.000\n",
       "147504  253657.453125  259200.000\n",
       "147505  254669.343750  259200.000\n",
       "147506  124639.265625  194662.671\n",
       "147507  125306.320312    6907.243\n",
       "147508  254432.859375  259200.000\n",
       "147509  252354.500000  259200.000\n",
       "147510  251663.531250  259200.000\n",
       "147511  124028.742188  179345.230\n",
       "147512  253056.562500  259200.000\n",
       "147513  253004.156250  259200.000\n",
       "147514  124135.101562   67690.731\n",
       "\n",
       "[147515 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"pred\":pred2,\"real\":real2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
